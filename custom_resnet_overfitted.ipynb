{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "custom_resnet_overfitted.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMiMPXDRDDrQLq38bgwnqMT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3815ccf501ff477d84877fbf5da68663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a910b5f4d58346ee9dba6d31f665ed86",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0c63d3006438407a96d51d28c4a32e17",
              "IPY_MODEL_c248b0687db54b24ac517cd549747749"
            ]
          }
        },
        "a910b5f4d58346ee9dba6d31f665ed86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c63d3006438407a96d51d28c4a32e17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b30ae6dadfea414780a7e89d5cabded8",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a93363cb98684e37bb44d1c6108c918d"
          }
        },
        "c248b0687db54b24ac517cd549747749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7977f635acd742989acc3e20f63068a2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [04:05&lt;00:00,  2.45s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e4c0e58e4c74459c815476e66e40db34"
          }
        },
        "b30ae6dadfea414780a7e89d5cabded8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a93363cb98684e37bb44d1c6108c918d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7977f635acd742989acc3e20f63068a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e4c0e58e4c74459c815476e66e40db34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshita23sharma/computer_vision/blob/main/custom_resnet_overfitted.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQKQca4Ggkso"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFljot71CSQc",
        "outputId": "d6ddd386-83b7-492f-a187-ea894771f9e2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lepZY0XwCd4R"
      },
      "source": [
        "!cd /content/drive/"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uFVyU-DCwfO"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoXZpxSnCjL5",
        "outputId": "c51f9176-b3bc-40dd-d3cd-26590489950c"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXN2jN0tU9qM",
        "outputId": "ab4046bb-801f-4045-ad65-9ea2c8abe71b"
      },
      "source": [
        "%rm -rf 'CIFAR_10'\n",
        "!git clone https://github.com/amanjain487/CIFAR_10"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CIFAR_10'...\n",
            "remote: Enumerating objects: 267, done.\u001b[K\n",
            "remote: Counting objects: 100% (267/267), done.\u001b[K\n",
            "remote: Compressing objects: 100% (260/260), done.\u001b[K\n",
            "remote: Total 267 (delta 130), reused 5 (delta 1), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (267/267), 63.08 KiB | 2.63 MiB/s, done.\n",
            "Resolving deltas: 100% (130/130), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8uOPgHi8hi9",
        "outputId": "91907b61-9615-4827-a804-8672b02287bc"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/CIFAR_10/')\n",
        "# from CIFAR_10 import utils\n",
        "# from CIFAR_10 import main\n",
        "# from CIFAR_10.GradCAM.visualize import VisualizeCam\n",
        "\n",
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "\n",
        "import torch"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsI3nb9t56Bi",
        "outputId": "f2a0ca68-2578-47d1-c86d-ac06d723d244"
      },
      "source": [
        "!pip install git+https://github.com/albumentations-team/albumentations.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/albumentations-team/albumentations.git\n",
            "  Cloning https://github.com/albumentations-team/albumentations.git to /tmp/pip-req-build-ntt5t968\n",
            "  Running command git clone -q https://github.com/albumentations-team/albumentations.git /tmp/pip-req-build-ntt5t968\n",
            "Requirement already satisfied (use --upgrade to upgrade): albumentations==1.0.2 from git+https://github.com/albumentations-team/albumentations.git in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==1.0.2) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==1.0.2) (1.4.1)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==1.0.2) (0.16.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==1.0.2) (3.13)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==1.0.2) (4.1.2.30)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.0.2) (7.1.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.0.2) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.0.2) (2.5.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.0.2) (1.1.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.0.2) (3.1.3)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations==1.0.2) (4.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.0.2) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.0.2) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.0.2) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.0.2) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.0.2) (1.15.0)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-1.0.2-cp37-none-any.whl size=98523 sha256=172f574bcf6b1e79323713c5d4acd2f8cb486e35807ec51675ef2849f8871309\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9x_ilsvt/wheels/e2/85/3e/2a40fac5cc1f43ced656603bb2fca1327b30ec7de1b1b66517\n",
            "Successfully built albumentations\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFMa5R4k8PDL"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "# from CIFAR_10.models.reimport torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.maxpool1 = nn.MaxPool2d(2,2)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                self.conv2,\n",
        "                self.bn2,\n",
        "                nn.ReLU()\n",
        "                \n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out1 = F.relu(self.bn1(self.maxpool1(self.conv1(x))))\n",
        "        out = F.relu(self.bn2(self.conv2(out1)))\n",
        "        out = self.shortcut(out)\n",
        "        # out += out1\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class BasicBlock2(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock2, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes, 1)\n",
        "        self.max_pool = nn.MaxPool2d(2,2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.max_pool(self.conv1(x))))\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "class ResNetCustom(nn.Module):\n",
        "    def __init__(self, block, block2, num_blocks, num_classes=10):\n",
        "        super(ResNetCustom, self).__init__()\n",
        "\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "\n",
        "        # self._prep_layer = F.relu(self.bn1(self.conv1(x)))\n",
        "\n",
        "        self.layer1 = self._make_layer(block, 128, num_blocks[0], stride=1)\n",
        "\n",
        "        self.layer2 = self._make_layer2(block2, 256, num_blocks[1], stride=1)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(128, 256, kernel_size=3, stride=3, bias=False)\n",
        "        self.max_pool = nn.MaxPool2d(4,2)\n",
        "        self.bn2 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.layer3 = self._make_layer(block, 512, num_blocks[2], stride=1)\n",
        "\n",
        "        self.max_pool2 = nn.MaxPool2d(4)\n",
        "        self.softmax = torch.nn.Softmax(dim=1)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    def _make_layer2(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        r1 = self.layer1(x)\n",
        "        out = self.layer2(r1)\n",
        "        r2 = self.layer3(out)\n",
        "        out = self.max_pool2(r2)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        out = self.softmax(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def CustomResNet():\n",
        "    return ResNetCustom(BasicBlock,BasicBlock2, [1, 1, 1],)\n",
        "\n",
        "\n",
        "# def test():\n",
        "#     net = CustomResNet()\n",
        "#     # print(summary(net, input_size=(3, 32, 32)))\n",
        "#     y = net(torch.randn(1, 3, 32, 32))\n",
        "#     print(y.size())\n",
        "\n",
        "\n",
        "\n",
        "# test()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVvXSgbI-hFF"
      },
      "source": [
        "# import os\n",
        "import argparse\n",
        "\n",
        "\n",
        "# Training\n",
        "def train(epoch, net, criterion, optimizer, device, trainloader, train_losses, train_acc):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "    print('Train Loss: %.3f | Train Acc: %.3f%% (%d/%d)' % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "    train_losses.append(train_loss/(batch_idx+1))\n",
        "    train_acc.append(100.*correct/total)\n",
        "    return train_losses, train_acc\n",
        "\n",
        "\n",
        "def test(epoch, net, criterion, device, testloader, best_acc, test_losses, test_acc):\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    print('Test Loss: %.3f | Test Acc: %.3f%% (%d/%d)' % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "    \n",
        "    test_losses.append(test_loss/(batch_idx+1))\n",
        "    test_acc.append(100.*correct/total)\n",
        "    \n",
        "    # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "    return best_acc, test_losses, test_acc\n",
        "    \n",
        "\n",
        "\n",
        "def dataloaders(trainset, testset):\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=256, shuffle=True, num_workers=2)\n",
        "\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "    \n",
        "    return trainloader, testloader\n",
        "\n",
        "\n",
        "def start_training(no_of_epoch, net, criterion, optimizer, device, trainloader, testloader, best_acc, scheduler):\n",
        "    train_loss = []\n",
        "    train_acc = []\n",
        "    test_loss = []\n",
        "    test_acc = []\n",
        "    \n",
        "    for epoch in range(no_of_epoch):\n",
        "        train_loss, train_acc = train(epoch+1, net, criterion, optimizer, device, trainloader, train_loss, train_acc)\n",
        "        best_acc, test_loss, test_acc = test(epoch+1, net, criterion, device, testloader, best_acc, test_loss, test_acc)\n",
        "        scheduler.step(test_loss[-1])\n",
        "    print(\"Best Acc is : \", best_acc)\n",
        "    return train_loss, train_acc, test_loss, test_acc\n",
        "\n",
        "        \n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNrdITYNLmoh",
        "outputId": "d3fe9c75-391d-4c2b-f072-e53cb6c1aa93"
      },
      "source": [
        "!pip install torch-lr-finder\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch-lr-finder in /usr/local/lib/python3.7/dist-packages (0.2.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (20.9)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (1.9.0+cu102)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (3.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (4.41.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torch-lr-finder) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->torch-lr-finder) (3.7.4.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->torch-lr-finder) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKu_gUgKC8cp"
      },
      "source": [
        "def define_model_utilities(model,momentum, loss=\"cross_entropy\", optimizer_func=\"SGD\", start_lr=0.001):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    best_acc = 0  # best test accuracy\n",
        "    classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "    net = model\n",
        "    net = net.to(device)\n",
        "     \n",
        "    if loss==\"cross_entropy\":\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    if optimizer_func==\"SGD\":\n",
        "        optimizer = optim.SGD(net.parameters(), lr=start_lr,\n",
        "                      momentum=0.9, weight_decay=5e-6)\n",
        "        # optimizer = optim.SGD(net.parameters(), start_lr=0.1, momentum)  # Create optimizer\n",
        "        # optimizer = optim.Adam(model.parameters(), lr=0.1, weight_decay=1e-2)\n",
        "\n",
        "\n",
        "    \n",
        "    # scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, 1, total_steps=None, epochs=None, steps_per_epoch=None)\n",
        "    # scheduler = StepLR(optimizer, lr_step_size, lr_gamma)\n",
        "    \n",
        "    # return device, best_acc, classes, net, criterion, optimizer, scheduler\n",
        "    return device, best_acc, classes, net, criterion, optimizer\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvabqEdCLtON",
        "outputId": "0b904457-5020-490e-e493-57a7c6ede664"
      },
      "source": [
        "!pip install torch-lr-finder\n",
        "\n",
        "from torch_lr_finder import LRFinder\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch-lr-finder in /usr/local/lib/python3.7/dist-packages (0.2.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (4.41.1)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (1.9.0+cu102)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (20.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (3.1.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->torch-lr-finder) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torch-lr-finder) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->torch-lr-finder) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onTrUesoEGfE"
      },
      "source": [
        "# # Get best initial learning rate\n",
        "# initial_lr = lr_finder.best_lr\n",
        "\n",
        "# # Print learning rate and loss\n",
        "# print('Learning Rate:', initial_lr)\n",
        "# print('Loss:', lr_finder.best_loss)\n",
        "\n",
        "# # Plot learning rate vs loss\n",
        "# lr_finder.plot()\n",
        "\n",
        "# # Reset graph\n",
        "# lr_finder.reset()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cya7NqN9ZJ_Z",
        "outputId": "d5076387-d2e7-41c1-a32f-b7bfa480b00d"
      },
      "source": [
        "!python -m pip install -U matplotlib"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting matplotlib\n",
            "  Using cached https://files.pythonhosted.org/packages/24/33/5568d443ba438d95d4db635dd69958056f087e57e1026bee56f959d53f9d/matplotlib-3.4.2-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
            "Installing collected packages: matplotlib\n",
            "  Found existing installation: matplotlib 3.1.3\n",
            "    Uninstalling matplotlib-3.1.3:\n",
            "      Successfully uninstalled matplotlib-3.1.3\n",
            "Successfully installed matplotlib-3.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_ZTqalO_U39"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import albumentations as A\n",
        "\n",
        "\n",
        "class CIFAR_10_Dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self,  dataset, transformer=None):\n",
        "        self.dataset = dataset\n",
        "        self.transforms = transformer\n",
        "  def __len__(self):\n",
        "        return len(self.dataset)\n",
        "  def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        img, target = self.dataset[idx]\n",
        "        img = img.cpu().detach().numpy()\n",
        "        img = np.asarray(img).reshape((32,32,3))\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(image=img)\n",
        "        img = torch.from_numpy(img.reshape(3,32,32))\n",
        "        return img, target\n",
        "\n",
        "\n",
        "def train_transform(train):\n",
        "  albumentation_train_list = []\n",
        "  train_list = []\n",
        "  for i in train:\n",
        "    if i == \"totensor\":\n",
        "      train_list.append(transforms.ToTensor())\n",
        "    if i == \"normalize_normal\":\n",
        "      train_list.append(transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)))\n",
        "    if i == \"normalize_mean\":\n",
        "      train_list.append(transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)))\n",
        "    if i == \"randomcrop\":\n",
        "      train_list.append(transforms.RandomCrop(32, padding=4))\n",
        "    if i == \"horizontal_flip\" or i == \"flipLR\":\n",
        "      train_list.append(transforms.RandomHorizontalFlip())\n",
        "    if i == \"random_rotate\":\n",
        "      train_list.append(transforms.RandomRotation((-5.0, 5.0), fill=(0,0,0)))\n",
        "    if i == \"cutout\":\n",
        "      albumentation_train_list.append(A.CoarseDropout(p=0.5, max_holes = 1, max_height=8, max_width=8, min_holes = 1, min_height=8, min_width=8, fill_value=(0.4914, 0.4822, 0.4465), mask_fill_value = None))\n",
        "    if i == \"shift_scale_rotate\":\n",
        "       albumentation_train_list.append(A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5))\n",
        "    if i == \"grayscale\":\n",
        "       albumentation_train_list.append(A.ToGray(p=0.5))\n",
        "  \n",
        "  return transforms.Compose(train_list), A.Compose(albumentation_train_list)\n",
        "\n",
        "\n",
        "\n",
        "def load_dataset(tensor_train, numpy_train):\n",
        "  train_dataset = CIFAR_10_Dataset(torchvision.datasets.CIFAR10(root='./data', train=True, download=True,\n",
        "                                  transform=tensor_train), numpy_train)\n",
        "\n",
        "  testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transforms.Compose([transforms.ToTensor(),\n",
        "                                                                                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "                                                                                   ]))\n",
        "  return train_dataset, testset\n",
        "\n",
        "\n",
        "def plot_graph(tr_l, tr_a, te_l, te_a):\n",
        "  fig, axs = plt.subplots(2,2,figsize=(15,10))\n",
        "  axs[0, 0].plot(tr_l)\n",
        "  axs[0, 0].set_title(\"Training Loss\")\n",
        "  axs[1, 0].plot(tr_a)\n",
        "  axs[1, 0].set_title(\"Training Accuracy\")\n",
        "  axs[0, 1].plot(te_l)\n",
        "  axs[0, 1].set_title(\"Test Loss\")\n",
        "  axs[1, 1].plot(te_a)\n",
        "  axs[1, 1].set_title(\"Test Accuracy\")\n",
        "\n",
        "\n",
        "def denormalize(tensor, mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]):\n",
        "    single_img = False\n",
        "    if tensor.ndimension() == 3:\n",
        "      single_img = True\n",
        "      tensor = tensor[None,:,:,:]\n",
        "\n",
        "    if not tensor.ndimension() == 4:\n",
        "        raise TypeError('tensor should be 4D')\n",
        "\n",
        "    mean = torch.FloatTensor(mean).view(1, 3, 1, 1).expand_as(tensor).to(tensor.device)\n",
        "    std = torch.FloatTensor(std).view(1, 3, 1, 1).expand_as(tensor).to(tensor.device)\n",
        "    ret = tensor.mul(std).add(mean)\n",
        "    return ret[0] if single_img else ret\n",
        "\n",
        "  \n",
        "def identify_images(net, criterion, device, testloader, n):\n",
        "    net.eval()\n",
        "    correct_images = []\n",
        "    incorrect_images = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)           \n",
        "            predicted = outputs.argmax(dim=1, keepdim=True)\n",
        "            is_correct = predicted.eq(targets.view_as(predicted))\n",
        "            \n",
        "            misclassified_inds = (is_correct==0).nonzero()[:,0]\n",
        "            for mis_ind in misclassified_inds:\n",
        "              if len(incorrect_images) == n:\n",
        "                break\n",
        "              incorrect_images.append({\n",
        "                  \"target\": targets[mis_ind].cpu().numpy(),\n",
        "                  \"pred\": predicted[mis_ind][0].cpu().numpy(),\n",
        "                  \"img\": inputs[mis_ind]\n",
        "              })\n",
        "\n",
        "            correct_inds = (is_correct==1).nonzero()[:,0]\n",
        "            for ind in correct_inds:\n",
        "              if len(correct_images) == n:\n",
        "                break\n",
        "              correct_images.append({\n",
        "                  \"target\": targets[ind].cpu().numpy(),\n",
        "                  \"pred\": predicted[ind][0].cpu().numpy(),\n",
        "                  \"img\": inputs[ind]\n",
        "              })\n",
        "    return correct_images, incorrect_images\n",
        "  \n",
        "  \n",
        "def plot_images(img_data, classes):\n",
        "    figure = plt.figure(figsize=(10, 10))\n",
        "\n",
        "    num_of_images = len(img_data)\n",
        "    for index in range(1, num_of_images + 1):\n",
        "        img = denormalize(img_data[index-1][\"img\"])  # unnormalize\n",
        "        plt.subplot(5, 5, index)\n",
        "        plt.axis('off')\n",
        "        img = img.cpu().numpy()\n",
        "        maxValue = np.amax(img)\n",
        "        minValue = np.amin(img)\n",
        "        img = np.clip(img, 0, 1)\n",
        "        img = img/np.amax(img)\n",
        "        img = np.clip(img, 0, 1)\n",
        "        plt.imshow(np.transpose(img, (1, 2, 0)))\n",
        "        plt.title(\"Predicted: %s\\nActual: %s\" % (classes[img_data[index-1][\"pred\"]], classes[img_data[index-1][\"target\"]]))\n",
        "\n",
        "    plt.tight_layout()\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8p0P-WsoAF4w"
      },
      "source": [
        "# !sudo pip3 install torchvision --upgrade"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlqnVd16AQqE"
      },
      "source": [
        "# !conda uninstall torchvision\n",
        "# !pip install torchvision"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMay8B_e5wxA"
      },
      "source": [
        "tensor_transforms, numpy_transforms = train_transform([\"randomcrop\", \"horizontal_flip\", \"cutout\"\n",
        ", \"totensor\"\n",
        ",\"normalize_normal\"\n",
        "])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rdy1xa84Uz5d",
        "outputId": "c769f334-d3b6-46c1-c975-a0c32b8f84ba"
      },
      "source": [
        "train_set, test_set = load_dataset(tensor_transforms, numpy_transforms)\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAS_r2hiUwCM"
      },
      "source": [
        "train_loader, test_loader = dataloaders(train_set, test_set)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAVd3Cv6Xoqj"
      },
      "source": [
        "model = CustomResNet()\n",
        "device, best_acc, classes, net, criterion, optimizer = define_model_utilities(model,\n",
        "                                                                              momentum=0.9,\n",
        "                                                                              loss=\"cross_entropy\", \n",
        "                                                                              optimizer_func=\"SGD\", \n",
        "                                                                              start_lr=0.01,\n",
        "                                                                              )"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "oMzkk3V2l5A3",
        "outputId": "0b2d9966-3fae-47ea-c86f-216ab3b50286"
      },
      "source": [
        "# !python -m pip uninstall matplotlib\n",
        "!pip install matplotlib==3.1.3"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting matplotlib==3.1.3\n",
            "  Using cached https://files.pythonhosted.org/packages/4c/9b/35ab3469fd1509f7636a344940569ebfd33239673fd2318e80b4700a257c/matplotlib-3.1.3-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib==3.1.3) (1.15.0)\n",
            "Installing collected packages: matplotlib\n",
            "  Found existing installation: matplotlib 3.4.2\n",
            "    Uninstalling matplotlib-3.4.2:\n",
            "      Successfully uninstalled matplotlib-3.4.2\n",
            "Successfully installed matplotlib-3.1.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438,
          "referenced_widgets": [
            "3815ccf501ff477d84877fbf5da68663",
            "a910b5f4d58346ee9dba6d31f665ed86",
            "0c63d3006438407a96d51d28c4a32e17",
            "c248b0687db54b24ac517cd549747749",
            "b30ae6dadfea414780a7e89d5cabded8",
            "a93363cb98684e37bb44d1c6108c918d",
            "7977f635acd742989acc3e20f63068a2",
            "e4c0e58e4c74459c815476e66e40db34"
          ]
        },
        "id": "nzPix_yFMRIK",
        "outputId": "dc35aacd-78df-4e10-874a-671fc2c7c6fc"
      },
      "source": [
        "# # # Find learning rate\n",
        "\n",
        "# from torch_lr_finder import LRFinder\n",
        "\n",
        "# lr_finder = LRFinder(net, optimizer, criterion, device=\"cuda\")\n",
        "# lr_finder.range_test(train_loader, val_loader=test_loader,end_lr=1, num_iter=100, step_mode=\"linear\")\n",
        "# lr_finder.plot() # to inspect the loss-learning rate graph\n",
        "# lr_finder.reset() # to reset the model and optimizer to their initial state\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3815ccf501ff477d84877fbf5da68663",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n",
            "LR suggestion: steepest gradient\n",
            "Suggested LR: 5.76E-01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQrgRFlnElA2"
      },
      "source": [
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.2, pct_start=0.208, steps_per_epoch=len(train_loader),\n",
        "                                                epochs=24,\n",
        "                                                base_momentum=0.3,\n",
        "                                                max_momentum = 0.9\n",
        "                                                )"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p76FnCYHflEP",
        "outputId": "4ce416fa-663f-4f5a-ffaf-349c9717d0c1"
      },
      "source": [
        "# train(10, net, criterion, optimizer, device, train_loader, train_losses, train_acc)\n",
        "\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "test_loss = []\n",
        "test_acc = []\n",
        "\n",
        "for epoch in range(24):\n",
        "    train_loss, train_acc = train(epoch+1, net, criterion, optimizer, device, train_loader, train_loss, train_acc)\n",
        "    best_acc, test_loss, test_acc = test(epoch+1, net, criterion, device, test_loader, best_acc, test_loss, test_acc)\n",
        "    scheduler.step(test_loss[-1])\n",
        "print(\"Best Acc is : \", best_acc)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1\n",
            "Train Loss: 2.100 | Train Acc: 35.828% (17914/50000)\n",
            "Test Loss: 2.119 | Test Acc: 33.610% (3361/10000)\n",
            "\n",
            "Epoch: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 1.955 | Train Acc: 50.926% (25463/50000)\n",
            "Test Loss: 2.150 | Test Acc: 30.320% (3032/10000)\n",
            "\n",
            "Epoch: 3\n",
            "Train Loss: 1.880 | Train Acc: 58.544% (29272/50000)\n",
            "Test Loss: 2.042 | Test Acc: 42.270% (4227/10000)\n",
            "\n",
            "Epoch: 4\n",
            "Train Loss: 1.822 | Train Acc: 64.446% (32223/50000)\n",
            "Test Loss: 2.024 | Test Acc: 43.770% (4377/10000)\n",
            "\n",
            "Epoch: 5\n",
            "Train Loss: 1.785 | Train Acc: 67.982% (33991/50000)\n",
            "Test Loss: 1.940 | Test Acc: 53.070% (5307/10000)\n",
            "\n",
            "Epoch: 6\n",
            "Train Loss: 1.762 | Train Acc: 70.152% (35076/50000)\n",
            "Test Loss: 1.918 | Test Acc: 55.010% (5501/10000)\n",
            "\n",
            "Epoch: 7\n",
            "Train Loss: 1.745 | Train Acc: 71.864% (35932/50000)\n",
            "Test Loss: 1.889 | Test Acc: 57.720% (5772/10000)\n",
            "\n",
            "Epoch: 8\n",
            "Train Loss: 1.714 | Train Acc: 75.178% (37589/50000)\n",
            "Test Loss: 1.859 | Test Acc: 60.360% (6036/10000)\n",
            "\n",
            "Epoch: 9\n",
            "Train Loss: 1.649 | Train Acc: 81.880% (40940/50000)\n",
            "Test Loss: 1.853 | Test Acc: 62.050% (6205/10000)\n",
            "\n",
            "Epoch: 10\n",
            "Train Loss: 1.634 | Train Acc: 83.120% (41560/50000)\n",
            "Test Loss: 1.845 | Test Acc: 62.060% (6206/10000)\n",
            "\n",
            "Epoch: 11\n",
            "Train Loss: 1.621 | Train Acc: 84.456% (42228/50000)\n",
            "Test Loss: 1.804 | Test Acc: 66.860% (6686/10000)\n",
            "\n",
            "Epoch: 12\n",
            "Train Loss: 1.613 | Train Acc: 85.280% (42640/50000)\n",
            "Test Loss: 1.799 | Test Acc: 67.320% (6732/10000)\n",
            "\n",
            "Epoch: 13\n",
            "Train Loss: 1.602 | Train Acc: 86.370% (43185/50000)\n",
            "Test Loss: 1.912 | Test Acc: 54.480% (5448/10000)\n",
            "\n",
            "Epoch: 14\n",
            "Train Loss: 1.596 | Train Acc: 86.924% (43462/50000)\n",
            "Test Loss: 1.822 | Test Acc: 64.620% (6462/10000)\n",
            "\n",
            "Epoch: 15\n",
            "Train Loss: 1.590 | Train Acc: 87.438% (43719/50000)\n",
            "Test Loss: 1.829 | Test Acc: 63.650% (6365/10000)\n",
            "\n",
            "Epoch: 16\n",
            "Train Loss: 1.582 | Train Acc: 88.328% (44164/50000)\n",
            "Test Loss: 1.810 | Test Acc: 65.480% (6548/10000)\n",
            "\n",
            "Epoch: 17\n",
            "Train Loss: 1.579 | Train Acc: 88.702% (44351/50000)\n",
            "Test Loss: 1.854 | Test Acc: 60.200% (6020/10000)\n",
            "\n",
            "Epoch: 18\n",
            "Train Loss: 1.573 | Train Acc: 89.198% (44599/50000)\n",
            "Test Loss: 1.784 | Test Acc: 67.830% (6783/10000)\n",
            "\n",
            "Epoch: 19\n",
            "Train Loss: 1.567 | Train Acc: 89.824% (44912/50000)\n",
            "Test Loss: 1.792 | Test Acc: 67.290% (6729/10000)\n",
            "\n",
            "Epoch: 20\n",
            "Train Loss: 1.564 | Train Acc: 90.130% (45065/50000)\n",
            "Test Loss: 1.794 | Test Acc: 66.790% (6679/10000)\n",
            "\n",
            "Epoch: 21\n",
            "Train Loss: 1.559 | Train Acc: 90.646% (45323/50000)\n",
            "Test Loss: 1.798 | Test Acc: 66.570% (6657/10000)\n",
            "\n",
            "Epoch: 22\n",
            "Train Loss: 1.556 | Train Acc: 90.870% (45435/50000)\n",
            "Test Loss: 1.810 | Test Acc: 65.630% (6563/10000)\n",
            "\n",
            "Epoch: 23\n",
            "Train Loss: 1.553 | Train Acc: 91.130% (45565/50000)\n",
            "Test Loss: 1.800 | Test Acc: 66.480% (6648/10000)\n",
            "\n",
            "Epoch: 24\n",
            "Train Loss: 1.549 | Train Acc: 91.618% (45809/50000)\n",
            "Test Loss: 1.756 | Test Acc: 70.770% (7077/10000)\n",
            "Best Acc is :  70.77\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8SqexALpv8t",
        "outputId": "cf316eb9-e4e7-4ab3-a886-756fc7ddd01e"
      },
      "source": [
        "# train(10, net, criterion, optimizer, device, train_loader, train_losses, train_acc)\n",
        "\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "test_loss = []\n",
        "test_acc = []\n",
        "\n",
        "for epoch in range(24):\n",
        "    train_loss, train_acc = train(epoch+1, net, criterion, optimizer, device, train_loader, train_loss, train_acc)\n",
        "    best_acc, test_loss, test_acc = test(epoch+1, net, criterion, device, test_loader, best_acc, test_loss, test_acc)\n",
        "    scheduler.step(test_loss[-1])\n",
        "print(\"Best Acc is : \", best_acc)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1\n",
            "Train Loss: 1.848 | Train Acc: 61.164% (30582/50000)\n",
            "Test Loss: 2.196 | Test Acc: 26.200% (2620/10000)\n",
            "\n",
            "Epoch: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 1.840 | Train Acc: 61.958% (30979/50000)\n",
            "Test Loss: 2.191 | Test Acc: 26.670% (2667/10000)\n",
            "\n",
            "Epoch: 3\n",
            "Train Loss: 1.836 | Train Acc: 62.338% (31169/50000)\n",
            "Test Loss: 2.189 | Test Acc: 26.850% (2685/10000)\n",
            "\n",
            "Epoch: 4\n",
            "Train Loss: 1.833 | Train Acc: 62.632% (31316/50000)\n",
            "Test Loss: 2.146 | Test Acc: 31.120% (3112/10000)\n",
            "\n",
            "Epoch: 5\n",
            "Train Loss: 1.831 | Train Acc: 62.796% (31398/50000)\n",
            "Test Loss: 2.158 | Test Acc: 29.900% (2990/10000)\n",
            "\n",
            "Epoch: 6\n",
            "Train Loss: 1.830 | Train Acc: 62.938% (31469/50000)\n",
            "Test Loss: 2.168 | Test Acc: 29.070% (2907/10000)\n",
            "\n",
            "Epoch: 7\n",
            "Train Loss: 1.826 | Train Acc: 63.360% (31680/50000)\n",
            "Test Loss: 2.187 | Test Acc: 27.190% (2719/10000)\n",
            "\n",
            "Epoch: 8\n",
            "Train Loss: 1.824 | Train Acc: 63.532% (31766/50000)\n",
            "Test Loss: 2.192 | Test Acc: 26.690% (2669/10000)\n",
            "\n",
            "Epoch: 9\n",
            "Train Loss: 1.821 | Train Acc: 63.786% (31893/50000)\n",
            "Test Loss: 2.180 | Test Acc: 27.660% (2766/10000)\n",
            "\n",
            "Epoch: 10\n",
            "Train Loss: 1.821 | Train Acc: 63.848% (31924/50000)\n",
            "Test Loss: 2.220 | Test Acc: 23.750% (2375/10000)\n",
            "\n",
            "Epoch: 11\n",
            "Train Loss: 1.818 | Train Acc: 64.106% (32053/50000)\n",
            "Test Loss: 2.156 | Test Acc: 30.040% (3004/10000)\n",
            "\n",
            "Epoch: 12\n",
            "Train Loss: 1.815 | Train Acc: 64.374% (32187/50000)\n",
            "Test Loss: 2.142 | Test Acc: 31.590% (3159/10000)\n",
            "\n",
            "Epoch: 13\n",
            "Train Loss: 1.815 | Train Acc: 64.372% (32186/50000)\n",
            "Test Loss: 2.110 | Test Acc: 34.740% (3474/10000)\n",
            "\n",
            "Epoch: 14\n",
            "Train Loss: 1.813 | Train Acc: 64.648% (32324/50000)\n",
            "Test Loss: 2.145 | Test Acc: 31.350% (3135/10000)\n",
            "\n",
            "Epoch: 15\n",
            "Train Loss: 1.811 | Train Acc: 64.872% (32436/50000)\n",
            "Test Loss: 2.156 | Test Acc: 30.120% (3012/10000)\n",
            "\n",
            "Epoch: 16\n",
            "Train Loss: 1.811 | Train Acc: 64.870% (32435/50000)\n",
            "Test Loss: 2.146 | Test Acc: 30.970% (3097/10000)\n",
            "\n",
            "Epoch: 17\n",
            "Train Loss: 1.808 | Train Acc: 65.144% (32572/50000)\n",
            "Test Loss: 2.138 | Test Acc: 31.980% (3198/10000)\n",
            "\n",
            "Epoch: 18\n",
            "Train Loss: 1.807 | Train Acc: 65.294% (32647/50000)\n",
            "Test Loss: 2.188 | Test Acc: 26.940% (2694/10000)\n",
            "\n",
            "Epoch: 19\n",
            "Train Loss: 1.805 | Train Acc: 65.486% (32743/50000)\n",
            "Test Loss: 2.151 | Test Acc: 30.410% (3041/10000)\n",
            "\n",
            "Epoch: 20\n",
            "Train Loss: 1.805 | Train Acc: 65.346% (32673/50000)\n",
            "Test Loss: 2.172 | Test Acc: 28.540% (2854/10000)\n",
            "\n",
            "Epoch: 21\n",
            "Train Loss: 1.803 | Train Acc: 65.614% (32807/50000)\n",
            "Test Loss: 2.176 | Test Acc: 27.940% (2794/10000)\n",
            "\n",
            "Epoch: 22\n",
            "Train Loss: 1.802 | Train Acc: 65.736% (32868/50000)\n",
            "Test Loss: 2.208 | Test Acc: 24.890% (2489/10000)\n",
            "\n",
            "Epoch: 23\n",
            "Train Loss: 1.802 | Train Acc: 65.742% (32871/50000)\n",
            "Test Loss: 2.130 | Test Acc: 32.590% (3259/10000)\n",
            "\n",
            "Epoch: 24\n",
            "Train Loss: 1.800 | Train Acc: 65.916% (32958/50000)\n",
            "Test Loss: 2.141 | Test Acc: 31.470% (3147/10000)\n",
            "Best Acc is :  34.74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF__Iai-axjg"
      },
      "source": [
        "# # Get best initial learning rate\n",
        "# initial_lr = lr_finder.best_lr\n",
        "\n",
        "# # Print learning rate and loss\n",
        "# print('Learning Rate:', initial_lr)\n",
        "# print('Loss:', lr_finder.best_loss)\n",
        "\n",
        "# # Plot learning rate vs loss\n",
        "# lr_finder.plot()\n",
        "\n",
        "# # Reset graph\n",
        "# lr_finder.reset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDv2yDkC9fUg"
      },
      "source": [
        "# def find_lr(init_value = 1e-8, final_value=10., beta = 0.98):\n",
        "#     num = len(train_loader)-1\n",
        "#     mult = (final_value / init_value) ** (1/num)\n",
        "#     lr = init_value\n",
        "#     optimizer.param_groups[0]['lr'] = lr\n",
        "#     avg_loss = 0.\n",
        "#     best_loss = 0.\n",
        "#     batch_num = 0\n",
        "#     losses = []\n",
        "#     log_lrs = []\n",
        "#     for data in train_loader:\n",
        "#         batch_num += 1\n",
        "#         #As before, get the loss for this mini-batch of inputs/outputs\n",
        "#         inputs,labels = data\n",
        "#         inputs, labels = inputs, labels\n",
        "#         optimizer.zero_grad()\n",
        "#         outputs = net(inputs)\n",
        "#         loss = criterion(outputs, labels)\n",
        "#         #Compute the smoothed loss\n",
        "#         avg_loss = beta * avg_loss + (1-beta) *loss.data[0]\n",
        "#         smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
        "#         #Stop if the loss is exploding\n",
        "#         if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
        "#             return log_lrs, losses\n",
        "#         #Record the best loss\n",
        "#         if smoothed_loss < best_loss or batch_num==1:\n",
        "#             best_loss = smoothed_loss\n",
        "#         #Store the values\n",
        "#         losses.append(smoothed_loss)\n",
        "#         log_lrs.append(math.log10(lr))\n",
        "#         #Do the SGD step\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         #Update the lr for the next step\n",
        "#         lr *= mult\n",
        "#         optimizer.param_groups[0]['lr'] = lr\n",
        "#     return log_lrs, losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9CfUVS-Bntv"
      },
      "source": [
        "# find_lr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZbcwJp4BpnE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}