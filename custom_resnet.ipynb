{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "custom_resnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMlmtXWJ4dRMsav1mSEMs5a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshita23sharma/computer_vision/blob/main/custom_resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8uOPgHi8hi9",
        "outputId": "e6427144-68f1-4d57-da16-ee4e8ed7a97f"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/CIFAR_10/')\n",
        "# from CIFAR_10 import utils\n",
        "# from CIFAR_10 import main\n",
        "# from CIFAR_10.GradCAM.visualize import VisualizeCam\n",
        "\n",
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "\n",
        "import torch"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFMa5R4k8PDL",
        "outputId": "571990c3-7df6-40dd-8213-00d45633d795"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "# from CIFAR_10.models.reimport torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride):\n",
        "        print(\"in_planes: \",in_planes)\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.maxpool1 = nn.MaxPool2d(2,2)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                self.conv2,\n",
        "                self.bn2,\n",
        "                nn.ReLU()\n",
        "                \n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out1 = F.relu(self.bn1(self.maxpool1(self.conv1(x))))\n",
        "        out = F.relu(self.bn2(self.conv2(out1)))\n",
        "        out = self.shortcut(out)\n",
        "        # F.relu(self.bn2(self.conv2(out)))\n",
        "        out += out1\n",
        "        print(\"OUT:\",out.shape)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class BasicBlock2(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        print(\"in_planes: \",in_planes)\n",
        "        super(BasicBlock2, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes, 1)\n",
        "        self.max_pool = nn.MaxPool2d(2,2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.max_pool(self.conv1(x))))\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "class ResNetCustom(nn.Module):\n",
        "    def __init__(self, block, block2, num_blocks, num_classes=10):\n",
        "        super(ResNetCustom, self).__init__()\n",
        "\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "\n",
        "        # self._prep_layer = F.relu(self.bn1(self.conv1(x)))\n",
        "\n",
        "        self.layer1 = self._make_layer(block, 128, num_blocks[0], stride=1)\n",
        "\n",
        "        self.layer2 = self._make_layer2(block2, 256, num_blocks[1], stride=1)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(128, 256, kernel_size=3, stride=3, bias=False)\n",
        "        self.max_pool = nn.MaxPool2d(4,2)\n",
        "        self.bn2 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.layer3 = self._make_layer(block, 512, num_blocks[2], stride=1)\n",
        "\n",
        "        self.max_pool2 = nn.MaxPool2d(4)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    def _make_layer2(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        r1 = self.layer1(x)\n",
        "        print(\"r1 : \",r1.shape)\n",
        "        out = self.layer2(r1)\n",
        "        print(out.shape) #([2, 128, 32, 32])\n",
        "        r2 = self.layer3(out)\n",
        "        out = self.max_pool2(r2)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        print(\"out shape\",out.shape)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def CustomResNet():\n",
        "    return ResNetCustom(BasicBlock,BasicBlock2, [1, 1, 1],)\n",
        "\n",
        "\n",
        "def test():\n",
        "    net = CustomResNet()\n",
        "    print(summary(net, input_size=(3, 32, 32)))\n",
        "    y = net(torch.randn(1, 3, 32, 32))\n",
        "    print(y.size())\n",
        "\n",
        "\n",
        "\n",
        "test()"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "in_planes:  64\n",
            "in_planes:  128\n",
            "in_planes:  256\n",
            "OUT: torch.Size([2, 128, 16, 16])\n",
            "r1 :  torch.Size([2, 128, 16, 16])\n",
            "torch.Size([2, 256, 8, 8])\n",
            "OUT: torch.Size([2, 512, 4, 4])\n",
            "out shape torch.Size([2, 512])\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "            Conv2d-3          [-1, 128, 32, 32]          73,728\n",
            "         MaxPool2d-4          [-1, 128, 16, 16]               0\n",
            "       BatchNorm2d-5          [-1, 128, 16, 16]             256\n",
            "            Conv2d-6          [-1, 128, 16, 16]         147,456\n",
            "            Conv2d-7          [-1, 128, 16, 16]         147,456\n",
            "       BatchNorm2d-8          [-1, 128, 16, 16]             256\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "           Conv2d-10          [-1, 128, 16, 16]         147,456\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "      BatchNorm2d-13          [-1, 128, 16, 16]             256\n",
            "             ReLU-14          [-1, 128, 16, 16]               0\n",
            "       BasicBlock-15          [-1, 128, 16, 16]               0\n",
            "           Conv2d-16          [-1, 256, 16, 16]         294,912\n",
            "        MaxPool2d-17            [-1, 256, 8, 8]               0\n",
            "      BatchNorm2d-18            [-1, 256, 8, 8]             512\n",
            "      BasicBlock2-19            [-1, 256, 8, 8]               0\n",
            "           Conv2d-20            [-1, 512, 8, 8]       1,179,648\n",
            "        MaxPool2d-21            [-1, 512, 4, 4]               0\n",
            "      BatchNorm2d-22            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-23            [-1, 512, 4, 4]       2,359,296\n",
            "           Conv2d-24            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-25            [-1, 512, 4, 4]           1,024\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-27            [-1, 512, 4, 4]       2,359,296\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "      BatchNorm2d-30            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-31            [-1, 512, 4, 4]               0\n",
            "       BasicBlock-32            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-33            [-1, 512, 1, 1]               0\n",
            "           Linear-34                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,589,194\n",
            "Trainable params: 11,589,194\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.88\n",
            "Params size (MB): 44.21\n",
            "Estimated Total Size (MB): 51.10\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "OUT: torch.Size([1, 128, 16, 16])\n",
            "r1 :  torch.Size([1, 128, 16, 16])\n",
            "torch.Size([1, 256, 8, 8])\n",
            "OUT: torch.Size([1, 512, 4, 4])\n",
            "out shape torch.Size([1, 512])\n",
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVvXSgbI-hFF"
      },
      "source": [
        "import os\n",
        "import argparse\n",
        "\n",
        "\n",
        "# Training\n",
        "def train(epoch, net, criterion, optimizer, device, trainloader, train_losses, train_acc):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "    print('Train Loss: %.3f | Train Acc: %.3f%% (%d/%d)' % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "    train_losses.append(train_loss/(batch_idx+1))\n",
        "    train_acc.append(100.*correct/total)\n",
        "    return train_losses, train_acc\n",
        "\n",
        "\n",
        "def test(epoch, net, criterion, device, testloader, best_acc, test_losses, test_acc):\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    print('Test Loss: %.3f | Test Acc: %.3f%% (%d/%d)' % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "    \n",
        "    test_losses.append(test_loss/(batch_idx+1))\n",
        "    test_acc.append(100.*correct/total)\n",
        "    \n",
        "    # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "    return best_acc, test_losses, test_acc\n",
        "    \n",
        "\n",
        "\n",
        "def dataloaders(trainset, testset):\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=4)\n",
        "\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=4)\n",
        "    \n",
        "    return trainloader, testloader\n",
        "\n",
        "\n",
        "def start_training(no_of_epoch, net, criterion, optimizer, device, trainloader, testloader, best_acc, scheduler):\n",
        "    train_loss = []\n",
        "    train_acc = []\n",
        "    test_loss = []\n",
        "    test_acc = []\n",
        "    \n",
        "    for epoch in range(no_of_epoch):\n",
        "        train_loss, train_acc = train(epoch+1, net, criterion, optimizer, device, trainloader, train_loss, train_acc)\n",
        "        best_acc, test_loss, test_acc = test(epoch+1, net, criterion, device, testloader, best_acc, test_loss, test_acc)\n",
        "        scheduler.step(test_loss[-1])\n",
        "    print(\"Best Acc is : \", best_acc)\n",
        "    return train_loss, train_acc, test_loss, test_acc\n",
        "\n",
        "        \n",
        "def define_model_utilities(loss=\"cross_entropy\", optimizer_func=\"SGD\", lr=0.1):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    best_acc = 0  # best test accuracy\n",
        "    classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "    net = CustomResNet()\n",
        "    net = net.to(device)\n",
        "     \n",
        "    if loss==\"cross_entropy\":\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    if optimizer_func==\"SGD\":\n",
        "        optimizer = optim.SGD(net.parameters(), lr=lr,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "        \n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3)\n",
        "    \n",
        "    return device, best_acc, classes, net, criterion, optimizer, scheduler\n"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1_T8ob89DHz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ded45ee-5d71-4b44-d077-46f1c33eb9d8"
      },
      "source": [
        "device, best_acc, classes, net, criterion, optimizer, scheduler = define_model_utilities(loss=\"cross_entropy\", optimizer_func=\"SGD\", lr=0.1)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "in_planes:  64\n",
            "in_planes:  128\n",
            "in_planes:  128\n",
            "in_planes:  256\n",
            "in_planes:  512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojaYU-pB9Qcm",
        "outputId": "f39dc818-a0d5-4613-ec04-191d6d4be00b"
      },
      "source": [
        "summary(net, input_size=(3, 32, 32))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 256, 6, 6])\n",
            "out shape torch.Size([2, 512])\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "            Conv2d-3          [-1, 128, 16, 16]          73,728\n",
            "       BatchNorm2d-4          [-1, 128, 16, 16]             256\n",
            "            Conv2d-5          [-1, 128, 16, 16]         147,456\n",
            "       BatchNorm2d-6          [-1, 128, 16, 16]             256\n",
            "            Conv2d-7          [-1, 128, 16, 16]           8,192\n",
            "       BatchNorm2d-8          [-1, 128, 16, 16]             256\n",
            "        BasicBlock-9          [-1, 128, 16, 16]               0\n",
            "           Conv2d-10          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-11          [-1, 128, 16, 16]             256\n",
            "           Conv2d-12          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-13          [-1, 128, 16, 16]             256\n",
            "       BasicBlock-14          [-1, 128, 16, 16]               0\n",
            "           Conv2d-15            [-1, 256, 6, 6]         294,912\n",
            "        MaxPool2d-16            [-1, 256, 6, 6]               0\n",
            "      BatchNorm2d-17            [-1, 256, 6, 6]             512\n",
            "      BasicBlock2-18            [-1, 256, 6, 6]               0\n",
            "           Conv2d-19            [-1, 512, 6, 6]       1,179,648\n",
            "      BatchNorm2d-20            [-1, 512, 6, 6]           1,024\n",
            "           Conv2d-21            [-1, 512, 6, 6]       2,359,296\n",
            "      BatchNorm2d-22            [-1, 512, 6, 6]           1,024\n",
            "           Conv2d-23            [-1, 512, 6, 6]         131,072\n",
            "      BatchNorm2d-24            [-1, 512, 6, 6]           1,024\n",
            "       BasicBlock-25            [-1, 512, 6, 6]               0\n",
            "           Conv2d-26            [-1, 512, 6, 6]       2,359,296\n",
            "      BatchNorm2d-27            [-1, 512, 6, 6]           1,024\n",
            "           Conv2d-28            [-1, 512, 6, 6]       2,359,296\n",
            "      BatchNorm2d-29            [-1, 512, 6, 6]           1,024\n",
            "       BasicBlock-30            [-1, 512, 6, 6]               0\n",
            "        MaxPool2d-31            [-1, 512, 1, 1]               0\n",
            "           Linear-32                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 9,221,706\n",
            "Trainable params: 9,221,706\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.97\n",
            "Params size (MB): 35.18\n",
            "Estimated Total Size (MB): 41.16\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDv2yDkC9fUg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}