{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "custom_resnet__less_overfitted.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOI1N9xOPcd84eN+A9a9QPL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ac4d0d7ec90d42d9917c19793e09fe98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4a25d3bf9ee24c90a8604466505bd321",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_01a5ff36462b46e9ac0239e2ab97fe5d",
              "IPY_MODEL_3ead9ff0d4174b42b25f32c00c448fbb"
            ]
          }
        },
        "4a25d3bf9ee24c90a8604466505bd321": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "01a5ff36462b46e9ac0239e2ab97fe5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4ad67dfc7c2d42dbbc1194866e32a447",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fa272598e8a64c36a0eb32edecf8535e"
          }
        },
        "3ead9ff0d4174b42b25f32c00c448fbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ff655fed428a4eaebf243c40b929c8d0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [03:57&lt;00:00,  2.38s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0b43395330e5405296506022735e54ec"
          }
        },
        "4ad67dfc7c2d42dbbc1194866e32a447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fa272598e8a64c36a0eb32edecf8535e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff655fed428a4eaebf243c40b929c8d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0b43395330e5405296506022735e54ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshita23sharma/computer_vision/blob/main/custom_resnet__less_overfitted.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQKQca4Ggkso"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFljot71CSQc",
        "outputId": "c6f66505-906f-4654-e7d5-ec0bdbe77614"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lepZY0XwCd4R"
      },
      "source": [
        "!cd /content/drive/"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uFVyU-DCwfO"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoXZpxSnCjL5",
        "outputId": "5e9f408c-fa53-43d0-eba0-9f8b200d60ab"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXN2jN0tU9qM",
        "outputId": "79c344da-fc0b-4421-e6be-565a2f7f3c6c"
      },
      "source": [
        "%rm -rf 'CIFAR_10'\n",
        "!git clone https://github.com/amanjain487/CIFAR_10"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CIFAR_10'...\n",
            "remote: Enumerating objects: 267, done.\u001b[K\n",
            "remote: Counting objects: 100% (267/267), done.\u001b[K\n",
            "remote: Compressing objects: 100% (260/260), done.\u001b[K\n",
            "remote: Total 267 (delta 130), reused 5 (delta 1), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (267/267), 63.08 KiB | 2.74 MiB/s, done.\n",
            "Resolving deltas: 100% (130/130), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8uOPgHi8hi9",
        "outputId": "5d9397dd-f4c8-446a-b65f-587bdefeecf2"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/CIFAR_10/')\n",
        "# from CIFAR_10 import utils\n",
        "# from CIFAR_10 import main\n",
        "# from CIFAR_10.GradCAM.visualize import VisualizeCam\n",
        "\n",
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "\n",
        "import torch"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsI3nb9t56Bi",
        "outputId": "36284592-1dd7-4f62-c0c1-5d754b98eee7"
      },
      "source": [
        "!pip install git+https://github.com/albumentations-team/albumentations.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/albumentations-team/albumentations.git\n",
            "  Cloning https://github.com/albumentations-team/albumentations.git to /tmp/pip-req-build-tw_4nyte\n",
            "  Running command git clone -q https://github.com/albumentations-team/albumentations.git /tmp/pip-req-build-tw_4nyte\n",
            "Requirement already satisfied (use --upgrade to upgrade): albumentations==1.0.2 from git+https://github.com/albumentations-team/albumentations.git in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==1.0.2) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==1.0.2) (1.4.1)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==1.0.2) (0.16.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==1.0.2) (3.13)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==1.0.2) (4.1.2.30)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.0.2) (7.1.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.0.2) (3.1.3)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.0.2) (2.5.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.0.2) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.0.2) (1.1.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.0.2) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.0.2) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.0.2) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.0.2) (1.3.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations==1.0.2) (4.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.0.2) (1.15.0)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-1.0.2-cp37-none-any.whl size=98523 sha256=eca56cfd9782c0dcf83b05341b0741648f0287f83df6b6ee3c10383cfab609e6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-duzp448l/wheels/e2/85/3e/2a40fac5cc1f43ced656603bb2fca1327b30ec7de1b1b66517\n",
            "Successfully built albumentations\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFMa5R4k8PDL"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "# from CIFAR_10.models.reimport torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.maxpool1 = nn.MaxPool2d(2,2)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                self.conv2,\n",
        "                self.bn2,\n",
        "                nn.ReLU()\n",
        "                \n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out1 = F.relu(self.bn1(self.maxpool1(self.conv1(x))))\n",
        "        out = F.relu(self.bn2(self.conv2(out1)))\n",
        "        out = self.shortcut(out)\n",
        "        out += out1\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class BasicBlock2(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock2, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes, 1)\n",
        "        self.max_pool = nn.MaxPool2d(2,2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.max_pool(self.conv1(x))))\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "class ResNetCustom(nn.Module):\n",
        "    def __init__(self, block, block2, num_blocks, num_classes=10):\n",
        "        super(ResNetCustom, self).__init__()\n",
        "\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "\n",
        "        # self._prep_layer = F.relu(self.bn1(self.conv1(x)))\n",
        "\n",
        "        self.layer1 = self._make_layer(block, 128, num_blocks[0], stride=1)\n",
        "\n",
        "        self.layer2 = self._make_layer2(block2, 256, num_blocks[1], stride=1)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(128, 256, kernel_size=3, stride=3, bias=False)\n",
        "        self.max_pool = nn.MaxPool2d(4,2)\n",
        "        self.bn2 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.layer3 = self._make_layer(block, 512, num_blocks[2], stride=1)\n",
        "\n",
        "        self.max_pool2 = nn.MaxPool2d(4)\n",
        "        self.softmax = torch.nn.Softmax(dim=1)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    def _make_layer2(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        r1 = self.layer1(x)\n",
        "        out = self.layer2(r1)\n",
        "        r2 = self.layer3(out)\n",
        "        out = self.max_pool2(r2)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        out = self.softmax(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def CustomResNet():\n",
        "    return ResNetCustom(BasicBlock,BasicBlock2, [1, 1, 1],)\n",
        "\n",
        "\n",
        "# def test():\n",
        "#     net = CustomResNet()\n",
        "#     # print(summary(net, input_size=(3, 32, 32)))\n",
        "#     y = net(torch.randn(1, 3, 32, 32))\n",
        "#     print(y.size())\n",
        "\n",
        "\n",
        "\n",
        "# test()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVvXSgbI-hFF"
      },
      "source": [
        "# import os\n",
        "import argparse\n",
        "\n",
        "\n",
        "# Training\n",
        "def train(epoch, net, criterion, optimizer, device, trainloader, train_losses, train_acc):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "    print('Train Loss: %.3f | Train Acc: %.3f%% (%d/%d)' % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "    train_losses.append(train_loss/(batch_idx+1))\n",
        "    train_acc.append(100.*correct/total)\n",
        "    return train_losses, train_acc\n",
        "\n",
        "\n",
        "def test(epoch, net, criterion, device, testloader, best_acc, test_losses, test_acc):\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    print('Test Loss: %.3f | Test Acc: %.3f%% (%d/%d)' % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "    \n",
        "    test_losses.append(test_loss/(batch_idx+1))\n",
        "    test_acc.append(100.*correct/total)\n",
        "    \n",
        "    # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "    return best_acc, test_losses, test_acc\n",
        "    \n",
        "\n",
        "\n",
        "def dataloaders(trainset, testset):\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=256, shuffle=True, num_workers=2)\n",
        "\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "    \n",
        "    return trainloader, testloader\n",
        "\n",
        "\n",
        "def start_training(no_of_epoch, net, criterion, optimizer, device, trainloader, testloader, best_acc, scheduler):\n",
        "    train_loss = []\n",
        "    train_acc = []\n",
        "    test_loss = []\n",
        "    test_acc = []\n",
        "    \n",
        "    for epoch in range(no_of_epoch):\n",
        "        train_loss, train_acc = train(epoch+1, net, criterion, optimizer, device, trainloader, train_loss, train_acc)\n",
        "        best_acc, test_loss, test_acc = test(epoch+1, net, criterion, device, testloader, best_acc, test_loss, test_acc)\n",
        "        scheduler.step(test_loss[-1])\n",
        "    print(\"Best Acc is : \", best_acc)\n",
        "    return train_loss, train_acc, test_loss, test_acc\n",
        "\n",
        "        \n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNrdITYNLmoh",
        "outputId": "70ee0e38-f80b-482f-bd57-ddcc66b93993"
      },
      "source": [
        "!pip install torch-lr-finder\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch-lr-finder in /usr/local/lib/python3.7/dist-packages (0.2.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (20.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (4.41.1)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (1.9.0+cu102)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (3.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (1.19.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torch-lr-finder) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->torch-lr-finder) (3.7.4.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->torch-lr-finder) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKu_gUgKC8cp"
      },
      "source": [
        "def define_model_utilities(model,momentum, loss=\"cross_entropy\", optimizer_func=\"SGD\", start_lr=0.001):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    best_acc = 0  # best test accuracy\n",
        "    classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "    net = model\n",
        "    net = net.to(device)\n",
        "     \n",
        "    if loss==\"cross_entropy\":\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    if optimizer_func==\"SGD\":\n",
        "        optimizer = optim.SGD(net.parameters(), lr=start_lr,\n",
        "                      momentum=0.9, weight_decay=5e-3)\n",
        "        # optimizer = optim.SGD(net.parameters(), start_lr=0.1, momentum)  # Create optimizer\n",
        "        # optimizer = optim.Adam(model.parameters(), lr=0.1, weight_decay=1e-2)\n",
        "\n",
        "\n",
        "    \n",
        "    # scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, 1, total_steps=None, epochs=None, steps_per_epoch=None)\n",
        "    # scheduler = StepLR(optimizer, lr_step_size, lr_gamma)\n",
        "    \n",
        "    # return device, best_acc, classes, net, criterion, optimizer, scheduler\n",
        "    return device, best_acc, classes, net, criterion, optimizer\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvabqEdCLtON",
        "outputId": "e2272537-37b1-4317-e7f2-68565f00affb"
      },
      "source": [
        "!pip install torch-lr-finder\n",
        "\n",
        "from torch_lr_finder import LRFinder\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch-lr-finder in /usr/local/lib/python3.7/dist-packages (0.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (3.1.3)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (1.9.0+cu102)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (20.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->torch-lr-finder) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->torch-lr-finder) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onTrUesoEGfE"
      },
      "source": [
        "# # Get best initial learning rate\n",
        "# initial_lr = lr_finder.best_lr\n",
        "\n",
        "# # Print learning rate and loss\n",
        "# print('Learning Rate:', initial_lr)\n",
        "# print('Loss:', lr_finder.best_loss)\n",
        "\n",
        "# # Plot learning rate vs loss\n",
        "# lr_finder.plot()\n",
        "\n",
        "# # Reset graph\n",
        "# lr_finder.reset()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cya7NqN9ZJ_Z",
        "outputId": "675266bf-340a-4f40-fb84-abd7cbb42464"
      },
      "source": [
        "!python -m pip install -U matplotlib"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting matplotlib\n",
            "  Using cached https://files.pythonhosted.org/packages/24/33/5568d443ba438d95d4db635dd69958056f087e57e1026bee56f959d53f9d/matplotlib-3.4.2-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
            "Installing collected packages: matplotlib\n",
            "  Found existing installation: matplotlib 3.1.3\n",
            "    Uninstalling matplotlib-3.1.3:\n",
            "      Successfully uninstalled matplotlib-3.1.3\n",
            "Successfully installed matplotlib-3.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_ZTqalO_U39"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import albumentations as A\n",
        "\n",
        "\n",
        "class CIFAR_10_Dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self,  dataset, transformer=None):\n",
        "        self.dataset = dataset\n",
        "        self.transforms = transformer\n",
        "  def __len__(self):\n",
        "        return len(self.dataset)\n",
        "  def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        img, target = self.dataset[idx]\n",
        "        img = img.cpu().detach().numpy()\n",
        "        img = np.asarray(img).reshape((32,32,3))\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(image=img)\n",
        "        img = torch.from_numpy(img.reshape(3,32,32))\n",
        "        return img, target\n",
        "\n",
        "\n",
        "def train_transform(train):\n",
        "  albumentation_train_list = []\n",
        "  train_list = []\n",
        "  for i in train:\n",
        "    if i == \"totensor\":\n",
        "      train_list.append(transforms.ToTensor())\n",
        "    if i == \"normalize_normal\":\n",
        "      train_list.append(transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)))\n",
        "    if i == \"normalize_mean\":\n",
        "      train_list.append(transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)))\n",
        "    if i == \"randomcrop\":\n",
        "      train_list.append(transforms.RandomCrop(32, padding=4))\n",
        "    if i == \"horizontal_flip\" or i == \"flipLR\":\n",
        "      train_list.append(transforms.RandomHorizontalFlip())\n",
        "    if i == \"random_rotate\":\n",
        "      train_list.append(transforms.RandomRotation((-5.0, 5.0), fill=(0,0,0)))\n",
        "    if i == \"cutout\":\n",
        "      albumentation_train_list.append(A.CoarseDropout(p=0.5, max_holes = 1, max_height=8, max_width=8, min_holes = 1, min_height=8, min_width=8, fill_value=(0.4914, 0.4822, 0.4465), mask_fill_value = None))\n",
        "    if i == \"shift_scale_rotate\":\n",
        "       albumentation_train_list.append(A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5))\n",
        "    if i == \"grayscale\":\n",
        "       albumentation_train_list.append(A.ToGray(p=0.5))\n",
        "  \n",
        "  return transforms.Compose(train_list), A.Compose(albumentation_train_list)\n",
        "\n",
        "\n",
        "\n",
        "def load_dataset(tensor_train, numpy_train):\n",
        "  train_dataset = CIFAR_10_Dataset(torchvision.datasets.CIFAR10(root='./data', train=True, download=True,\n",
        "                                  transform=tensor_train), numpy_train)\n",
        "\n",
        "  testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transforms.Compose([transforms.ToTensor(),\n",
        "                                                                                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "                                                                                   ]))\n",
        "  return train_dataset, testset\n",
        "\n",
        "\n",
        "def plot_graph(tr_l, tr_a, te_l, te_a):\n",
        "  fig, axs = plt.subplots(2,2,figsize=(15,10))\n",
        "  axs[0, 0].plot(tr_l)\n",
        "  axs[0, 0].set_title(\"Training Loss\")\n",
        "  axs[1, 0].plot(tr_a)\n",
        "  axs[1, 0].set_title(\"Training Accuracy\")\n",
        "  axs[0, 1].plot(te_l)\n",
        "  axs[0, 1].set_title(\"Test Loss\")\n",
        "  axs[1, 1].plot(te_a)\n",
        "  axs[1, 1].set_title(\"Test Accuracy\")\n",
        "\n",
        "\n",
        "def denormalize(tensor, mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]):\n",
        "    single_img = False\n",
        "    if tensor.ndimension() == 3:\n",
        "      single_img = True\n",
        "      tensor = tensor[None,:,:,:]\n",
        "\n",
        "    if not tensor.ndimension() == 4:\n",
        "        raise TypeError('tensor should be 4D')\n",
        "\n",
        "    mean = torch.FloatTensor(mean).view(1, 3, 1, 1).expand_as(tensor).to(tensor.device)\n",
        "    std = torch.FloatTensor(std).view(1, 3, 1, 1).expand_as(tensor).to(tensor.device)\n",
        "    ret = tensor.mul(std).add(mean)\n",
        "    return ret[0] if single_img else ret\n",
        "\n",
        "  \n",
        "def identify_images(net, criterion, device, testloader, n):\n",
        "    net.eval()\n",
        "    correct_images = []\n",
        "    incorrect_images = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)           \n",
        "            predicted = outputs.argmax(dim=1, keepdim=True)\n",
        "            is_correct = predicted.eq(targets.view_as(predicted))\n",
        "            \n",
        "            misclassified_inds = (is_correct==0).nonzero()[:,0]\n",
        "            for mis_ind in misclassified_inds:\n",
        "              if len(incorrect_images) == n:\n",
        "                break\n",
        "              incorrect_images.append({\n",
        "                  \"target\": targets[mis_ind].cpu().numpy(),\n",
        "                  \"pred\": predicted[mis_ind][0].cpu().numpy(),\n",
        "                  \"img\": inputs[mis_ind]\n",
        "              })\n",
        "\n",
        "            correct_inds = (is_correct==1).nonzero()[:,0]\n",
        "            for ind in correct_inds:\n",
        "              if len(correct_images) == n:\n",
        "                break\n",
        "              correct_images.append({\n",
        "                  \"target\": targets[ind].cpu().numpy(),\n",
        "                  \"pred\": predicted[ind][0].cpu().numpy(),\n",
        "                  \"img\": inputs[ind]\n",
        "              })\n",
        "    return correct_images, incorrect_images\n",
        "  \n",
        "  \n",
        "def plot_images(img_data, classes):\n",
        "    figure = plt.figure(figsize=(10, 10))\n",
        "\n",
        "    num_of_images = len(img_data)\n",
        "    for index in range(1, num_of_images + 1):\n",
        "        img = denormalize(img_data[index-1][\"img\"])  # unnormalize\n",
        "        plt.subplot(5, 5, index)\n",
        "        plt.axis('off')\n",
        "        img = img.cpu().numpy()\n",
        "        maxValue = np.amax(img)\n",
        "        minValue = np.amin(img)\n",
        "        img = np.clip(img, 0, 1)\n",
        "        img = img/np.amax(img)\n",
        "        img = np.clip(img, 0, 1)\n",
        "        plt.imshow(np.transpose(img, (1, 2, 0)))\n",
        "        plt.title(\"Predicted: %s\\nActual: %s\" % (classes[img_data[index-1][\"pred\"]], classes[img_data[index-1][\"target\"]]))\n",
        "\n",
        "    plt.tight_layout()\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8p0P-WsoAF4w"
      },
      "source": [
        "# !sudo pip3 install torchvision --upgrade"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlqnVd16AQqE"
      },
      "source": [
        "# !conda uninstall torchvision\n",
        "# !pip install torchvision"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMay8B_e5wxA"
      },
      "source": [
        "tensor_transforms, numpy_transforms = train_transform([\"randomcrop\", \"horizontal_flip\", \"cutout\"\n",
        ", \"totensor\"\n",
        ",\"normalize_mean\"\n",
        "])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rdy1xa84Uz5d",
        "outputId": "dd729bdc-03e6-4284-c8ab-020bd56d4e2e"
      },
      "source": [
        "train_set, test_set = load_dataset(tensor_transforms, numpy_transforms)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAS_r2hiUwCM"
      },
      "source": [
        "train_loader, test_loader = dataloaders(train_set, test_set)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAVd3Cv6Xoqj"
      },
      "source": [
        "model = CustomResNet()\n",
        "device, best_acc, classes, net, criterion, optimizer = define_model_utilities(model,\n",
        "                                                                              momentum=0.9,\n",
        "                                                                              loss=\"cross_entropy\", \n",
        "                                                                              optimizer_func=\"SGD\", \n",
        "                                                                              start_lr=0.1,\n",
        "                                                                              )"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "oMzkk3V2l5A3",
        "outputId": "d5c7a072-1693-471f-c3ab-7d5fad5ec39b"
      },
      "source": [
        "# !python -m pip uninstall matplotlib\n",
        "!pip install matplotlib==3.1.3"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting matplotlib==3.1.3\n",
            "  Using cached https://files.pythonhosted.org/packages/4c/9b/35ab3469fd1509f7636a344940569ebfd33239673fd2318e80b4700a257c/matplotlib-3.1.3-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib==3.1.3) (1.15.0)\n",
            "Installing collected packages: matplotlib\n",
            "  Found existing installation: matplotlib 3.4.2\n",
            "    Uninstalling matplotlib-3.4.2:\n",
            "      Successfully uninstalled matplotlib-3.4.2\n",
            "Successfully installed matplotlib-3.1.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438,
          "referenced_widgets": [
            "ac4d0d7ec90d42d9917c19793e09fe98",
            "4a25d3bf9ee24c90a8604466505bd321",
            "01a5ff36462b46e9ac0239e2ab97fe5d",
            "3ead9ff0d4174b42b25f32c00c448fbb",
            "4ad67dfc7c2d42dbbc1194866e32a447",
            "fa272598e8a64c36a0eb32edecf8535e",
            "ff655fed428a4eaebf243c40b929c8d0",
            "0b43395330e5405296506022735e54ec"
          ]
        },
        "id": "nzPix_yFMRIK",
        "outputId": "88ee98de-29cf-4ad1-af20-3f826cc13c50"
      },
      "source": [
        "# # Find learning rate\n",
        "\n",
        "from torch_lr_finder import LRFinder\n",
        "\n",
        "lr_finder = LRFinder(net, optimizer, criterion, device=\"cuda\")\n",
        "lr_finder.range_test(train_loader, val_loader=test_loader,end_lr=1, num_iter=100, step_mode=\"linear\")\n",
        "lr_finder.plot() # to inspect the loss-learning rate graph\n",
        "lr_finder.reset() # to reset the model and optimizer to their initial state\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac4d0d7ec90d42d9917c19793e09fe98",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n",
            "LR suggestion: steepest gradient\n",
            "Suggested LR: 2.45E-01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQrgRFlnElA2"
      },
      "source": [
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.245, pct_start=0.208, steps_per_epoch=len(train_loader),\n",
        "                                                epochs=24,\n",
        "                                                base_momentum=0.1,\n",
        "                                                max_momentum = 0.9\n",
        "                                                )"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoLb736xloga",
        "outputId": "1ceced9a-d9d2-4035-d694-460878357b59"
      },
      "source": [
        "# train(10, net, criterion, optimizer, device, train_loader, train_losses, train_acc)\n",
        "\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "test_loss = []\n",
        "test_acc = []\n",
        "\n",
        "for epoch in range(24):\n",
        "    train_loss, train_acc = train(epoch+1, net, criterion, optimizer, device, train_loader, train_loss, train_acc)\n",
        "    best_acc, test_loss, test_acc = test(epoch+1, net, criterion, device, test_loader, best_acc, test_loss, test_acc)\n",
        "    scheduler.step(test_loss[-1])\n",
        "print(\"Best Acc is : \", best_acc)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1\n",
            "Train Loss: 2.055 | Train Acc: 40.458% (20229/50000)\n",
            "Test Loss: 1.972 | Test Acc: 48.910% (4891/10000)\n",
            "\n",
            "Epoch: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 1.874 | Train Acc: 59.386% (29693/50000)\n",
            "Test Loss: 1.834 | Test Acc: 63.080% (6308/10000)\n",
            "\n",
            "Epoch: 3\n",
            "Train Loss: 1.782 | Train Acc: 68.952% (34476/50000)\n",
            "Test Loss: 1.792 | Test Acc: 67.550% (6755/10000)\n",
            "\n",
            "Epoch: 4\n",
            "Train Loss: 1.724 | Train Acc: 74.868% (37434/50000)\n",
            "Test Loss: 1.785 | Test Acc: 68.840% (6884/10000)\n",
            "\n",
            "Epoch: 5\n",
            "Train Loss: 1.691 | Train Acc: 78.190% (39095/50000)\n",
            "Test Loss: 1.733 | Test Acc: 73.580% (7358/10000)\n",
            "\n",
            "Epoch: 6\n",
            "Train Loss: 1.668 | Train Acc: 80.484% (40242/50000)\n",
            "Test Loss: 1.725 | Test Acc: 74.680% (7468/10000)\n",
            "\n",
            "Epoch: 7\n",
            "Train Loss: 1.647 | Train Acc: 82.588% (41294/50000)\n",
            "Test Loss: 1.680 | Test Acc: 79.760% (7976/10000)\n",
            "\n",
            "Epoch: 8\n",
            "Train Loss: 1.635 | Train Acc: 83.902% (41951/50000)\n",
            "Test Loss: 1.697 | Test Acc: 78.130% (7813/10000)\n",
            "\n",
            "Epoch: 9\n",
            "Train Loss: 1.625 | Train Acc: 85.090% (42545/50000)\n",
            "Test Loss: 1.696 | Test Acc: 77.770% (7777/10000)\n",
            "\n",
            "Epoch: 10\n",
            "Train Loss: 1.614 | Train Acc: 86.366% (43183/50000)\n",
            "Test Loss: 1.658 | Test Acc: 82.760% (8276/10000)\n",
            "\n",
            "Epoch: 11\n",
            "Train Loss: 1.608 | Train Acc: 87.046% (43523/50000)\n",
            "Test Loss: 1.650 | Test Acc: 82.930% (8293/10000)\n",
            "\n",
            "Epoch: 12\n",
            "Train Loss: 1.601 | Train Acc: 87.800% (43900/50000)\n",
            "Test Loss: 1.647 | Test Acc: 83.430% (8343/10000)\n",
            "\n",
            "Epoch: 13\n",
            "Train Loss: 1.596 | Train Acc: 88.398% (44199/50000)\n",
            "Test Loss: 1.680 | Test Acc: 80.110% (8011/10000)\n",
            "\n",
            "Epoch: 14\n",
            "Train Loss: 1.592 | Train Acc: 88.856% (44428/50000)\n",
            "Test Loss: 1.645 | Test Acc: 84.630% (8463/10000)\n",
            "\n",
            "Epoch: 15\n",
            "Train Loss: 1.590 | Train Acc: 89.214% (44607/50000)\n",
            "Test Loss: 1.637 | Test Acc: 85.660% (8566/10000)\n",
            "\n",
            "Epoch: 16\n",
            "Train Loss: 1.587 | Train Acc: 89.726% (44863/50000)\n",
            "Test Loss: 1.671 | Test Acc: 82.440% (8244/10000)\n",
            "\n",
            "Epoch: 17\n",
            "Train Loss: 1.586 | Train Acc: 89.780% (44890/50000)\n",
            "Test Loss: 1.674 | Test Acc: 82.220% (8222/10000)\n",
            "\n",
            "Epoch: 18\n",
            "Train Loss: 1.583 | Train Acc: 90.138% (45069/50000)\n",
            "Test Loss: 1.701 | Test Acc: 80.910% (8091/10000)\n",
            "\n",
            "Epoch: 19\n",
            "Train Loss: 1.580 | Train Acc: 90.428% (45214/50000)\n",
            "Test Loss: 1.719 | Test Acc: 79.900% (7990/10000)\n",
            "\n",
            "Epoch: 20\n",
            "Train Loss: 1.582 | Train Acc: 90.310% (45155/50000)\n",
            "Test Loss: 1.723 | Test Acc: 78.990% (7899/10000)\n",
            "\n",
            "Epoch: 21\n",
            "Train Loss: 1.581 | Train Acc: 90.462% (45231/50000)\n",
            "Test Loss: 1.667 | Test Acc: 86.430% (8643/10000)\n",
            "\n",
            "Epoch: 22\n",
            "Train Loss: 1.582 | Train Acc: 90.334% (45167/50000)\n",
            "Test Loss: 1.768 | Test Acc: 78.460% (7846/10000)\n",
            "\n",
            "Epoch: 23\n",
            "Train Loss: 1.584 | Train Acc: 90.236% (45118/50000)\n",
            "Test Loss: 1.791 | Test Acc: 77.320% (7732/10000)\n",
            "\n",
            "Epoch: 24\n",
            "Train Loss: 1.582 | Train Acc: 90.230% (45115/50000)\n",
            "Test Loss: 1.773 | Test Acc: 78.470% (7847/10000)\n",
            "Best Acc is :  86.43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p76FnCYHflEP"
      },
      "source": [
        "# train(10, net, criterion, optimizer, device, train_loader, train_losses, train_acc)\n",
        "\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "test_loss = []\n",
        "test_acc = []\n",
        "\n",
        "for epoch in range(24):\n",
        "    train_loss, train_acc = train(epoch+1, net, criterion, optimizer, device, train_loader, train_loss, train_acc)\n",
        "    best_acc, test_loss, test_acc = test(epoch+1, net, criterion, device, test_loader, best_acc, test_loss, test_acc)\n",
        "    scheduler.step(test_loss[-1])\n",
        "print(\"Best Acc is : \", best_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8SqexALpv8t",
        "outputId": "2ebe2803-7ac2-4993-8ebe-9d4029f8fc87"
      },
      "source": [
        "# train(10, net, criterion, optimizer, device, train_loader, train_losses, train_acc)\n",
        "\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "test_loss = []\n",
        "test_acc = []\n",
        "\n",
        "for epoch in range(24):\n",
        "    train_loss, train_acc = train(epoch+1, net, criterion, optimizer, device, train_loader, train_loss, train_acc)\n",
        "    best_acc, test_loss, test_acc = test(epoch+1, net, criterion, device, test_loader, best_acc, test_loss, test_acc)\n",
        "    scheduler.step(test_loss[-1])\n",
        "print(\"Best Acc is : \", best_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1\n",
            "Train Loss: 1.498 | Train Acc: 96.778% (48389/50000)\n",
            "Test Loss: 1.767 | Test Acc: 70.040% (7004/10000)\n",
            "\n",
            "Epoch: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF__Iai-axjg"
      },
      "source": [
        "# # Get best initial learning rate\n",
        "# initial_lr = lr_finder.best_lr\n",
        "\n",
        "# # Print learning rate and loss\n",
        "# print('Learning Rate:', initial_lr)\n",
        "# print('Loss:', lr_finder.best_loss)\n",
        "\n",
        "# # Plot learning rate vs loss\n",
        "# lr_finder.plot()\n",
        "\n",
        "# # Reset graph\n",
        "# lr_finder.reset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDv2yDkC9fUg"
      },
      "source": [
        "# def find_lr(init_value = 1e-8, final_value=10., beta = 0.98):\n",
        "#     num = len(train_loader)-1\n",
        "#     mult = (final_value / init_value) ** (1/num)\n",
        "#     lr = init_value\n",
        "#     optimizer.param_groups[0]['lr'] = lr\n",
        "#     avg_loss = 0.\n",
        "#     best_loss = 0.\n",
        "#     batch_num = 0\n",
        "#     losses = []\n",
        "#     log_lrs = []\n",
        "#     for data in train_loader:\n",
        "#         batch_num += 1\n",
        "#         #As before, get the loss for this mini-batch of inputs/outputs\n",
        "#         inputs,labels = data\n",
        "#         inputs, labels = inputs, labels\n",
        "#         optimizer.zero_grad()\n",
        "#         outputs = net(inputs)\n",
        "#         loss = criterion(outputs, labels)\n",
        "#         #Compute the smoothed loss\n",
        "#         avg_loss = beta * avg_loss + (1-beta) *loss.data[0]\n",
        "#         smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
        "#         #Stop if the loss is exploding\n",
        "#         if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
        "#             return log_lrs, losses\n",
        "#         #Record the best loss\n",
        "#         if smoothed_loss < best_loss or batch_num==1:\n",
        "#             best_loss = smoothed_loss\n",
        "#         #Store the values\n",
        "#         losses.append(smoothed_loss)\n",
        "#         log_lrs.append(math.log10(lr))\n",
        "#         #Do the SGD step\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         #Update the lr for the next step\n",
        "#         lr *= mult\n",
        "#         optimizer.param_groups[0]['lr'] = lr\n",
        "#     return log_lrs, losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9CfUVS-Bntv"
      },
      "source": [
        "# find_lr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZbcwJp4BpnE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}